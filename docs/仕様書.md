# 各政党の考え方を可視化するアプリケーション 仕様書

- 文書ID: PartyViz-SPEC
- 版: v0.10
- 更新日: 2025-12-26
- 対象: 日本の政党（任意で政治家）

---

## 1. 目的

政策トピックごとに各政党（および任意で政治家）の立場を **1軸または2軸** のグラフ上に可視化し、判定根拠となる **公式一次情報（政党・政治家本人の公式ページ／公的機関ページ）** を参照できる形で提供する。  
本アプリは **投票先推薦を目的としない**。情報提供・比較閲覧を目的とする。

---

## 2. 基本方針

### 2.1 データソース制約
- 使用情報は以下に限定  
  1. 政党公式サイト（政策、綱領、マニフェスト、声明、プレスリリース等）  
  2. 政治家公式サイト（政策、国会活動報告、実績ページ等）  
  3. 公的機関サイト（国会・選管・e-Gov 等の一次データ）  
- **禁止**：本人以外のSNS、報道機関、第三者まとめサイト等
- 公式情報をデフォルトとし、必要時のみ **mixed（外部ページ併用）** を許可（任意機能）

### 2.2 監査可能性
- すべてのスコアは「根拠URL＋抜粋＋取得日時」を必須とする
- 根拠が不足する場合は無理に推定せず **「不明 / 言及なし」** とする
- 算出結果は **バージョン管理（ルーブリック版本・算出日時）** する

---

## 3. 機能要件

### 3.1 可視化機能
- トピックごとに表示  
  - 1軸: 左右配置（区間表示可）  
  - 2軸: 散布図  
- 表示対象切替: 政党のみ / 政党＋政治家（任意）  
- 表示モード切替: 主張（Claim） / 実績（Action） / 統合（Combined: 加重平均等）
- テーマ切替（暗/明の複数パターン）

### 3.2 スコアリング機能（生成AI利用）
- トピックごとに公式ページ群から生成  
  - 立場ラベル（例: 賛成 / 反対 / 条件付き / 言及なし / 不明）  
  - スコア（例: -100〜+100）  
  - 信頼度（0〜1）  
  - 根拠（URL、取得日時、抜粋、該当箇所）  
- 出力は **固定JSON**（後述）で保存・API提供する
- 公式ページのクロール/インデックスを優先し、必要時のみ検索ベースを補助利用
- **index_only**（インデックスのみ評価）と **mixed**（外部併用）は任意機能

### 3.3 根拠提示機能
スコア詳細画面で以下を表示する。  
参照した根拠URL一覧（取得日時・最終到達URL）、抜粋（引用範囲／テキスト）、判定理由（要約）、使用したトピック定義版本と算出日時。
評価基準（ルーブリック）は公開ページから参照可能とする。

### 3.4 巨大政党のレンジ化
- 政党公式見解が弱い、または政治家の見解が分散する場合は政党スコアを **点ではなく範囲（レンジ）** で表示
- レンジ定義（推奨）  
  - 政治家スコア集合の **P10〜P90** を範囲  
  - **中央値（P50）** を代表値として併記可能  
- 党公式見解が十分強い場合は政党公式を点として優先表示

---

## 4. 新機能: 新政党の自動登録（AIエージェント）

### 4.1 目的
新政党/政治団体が登場した際、運用者の手動登録なしで以下を自動化する。政党の検知、公式サイトURLの取得（根拠付き）、許可ドメイン登録、クロール・採点の自動トリガ。

### 4.2 自動発見（Discovery）
- 定期ジョブで公的機関ページ等から政党候補を抽出し差分検知  
- 検知結果は `candidate` として登録し、次工程へキュー投入

### 4.3 公式URL特定（Resolution）
- 公式URLは **根拠付きで確定**  
- 確定ルール  
  - 公的リンク集等に公式サイトURLが明示 → **自動確定（High confidence）**  
  - URL未記載／候補複数／到達不可 → `needs_review`（自動確定しない）  
- 自動確定後、最終到達URLのドメインを `allowed_domains` に登録

### 4.4 自動更新（変更検知）
- 党名変更、URL変更、リダイレクト・ドメイン移転を差分検知し履歴管理  
- 変更時はクロール・採点を再実行トリガ

---

## 5. 画面仕様（MVP想定）

### 5.1 トピック選択
- トピック一覧（リスト形式）  
- 表示モード: 1軸/2軸、主張/実績/統合、政党/政治家  
- 2軸はトピックを2つ選択して散布図を表示

### 5.2 可視化画面
- 点/レンジ表示  
- クリックで詳細パネルを開く
- 1軸/2軸の切替表示

### 5.3 詳細パネル
- スコア、ラベル、信頼度  
- 根拠URL＋抜粋（ハイライト）、判定理由要約  
- 算出日時、トピック定義版本

---

## 6. データ処理パイプライン

### 6.1 公式URL登録（自動）
1. 公的ページ取得（スナップショット化）  
2. 政党候補抽出  
3. 差分検知 → イベント生成  
4. 公式URL解決（到達確認、最終URL取得）  
5. `party_registry` 更新（status/allowed_domains/evidence）  
6. クロール・採点トリガ

### 6.2 クロール（公式ドメインのみ）
- allowlistドメイン配下のみ取得（混入防止）  
- 政党ごとの **政策起点URL** を登録し、その配下をクロール  
- HTML本文とPDFを取得（テキスト抽出可能なPDFのみ）  
- robots.txt尊重、レート制限、差分更新（hash変化があるページのみ再解析）

### 6.3 トピック分類 → 採点
- ページ本文抽出 → トピック分類（ルール＋必要に応じてLLM補助）  
- トピックごとに採点（固定JSON出力）  
- 根拠が不足する場合は **「不明 / 言及なし」**
- 公式インデックスを優先し、必要に応じて検索ベースを補助利用（mixedは任意）

---

## 7. スコア出力仕様（固定JSON）

保存・API返却の基礎形:

```json
{
  "entity_type": "party",
  "entity_id": "uuid",
  "topic_id": "tax",
  "mode": "claim",
  "stance_label": "conditional",
  "stance_score": 35,
  "confidence": 0.72,
  "rationale": "根拠抜粋に基づく要約",
  "evidence": [
    {
      "url": "https://example.jp/policy/...",
      "fetched_at": "2025-12-12T03:00:00Z",
      "quote": "…抜粋…",
      "quote_start": 1234,
      "quote_end": 1301
    }
  ],
  "meta": {
    "topic_version": "2025-12-01",
    "calc_version": "2025-12-12T03:30:00Z"
  }
}
```

---

## 8. データモデル（DB）

### 8.1 必須テーブル（自動登録対応）
- `party_registry`: 政党の状態・公式URL・allowlist・根拠（evidence）  
- `party_discovery_events`: 差分検知イベント（冪等キー含む）  
- `source_snapshots`: 公的ページ等のスナップショット（差分検知用）  
- `party_change_history`: URL変更・ステータス遷移等の履歴  
- `party_policy_sources`: 政策起点URL（複数）  
- `policy_documents`: クロールしたHTML/PDF本文  
- `policy_chunks`: 検索・参照用のチャンク  
※ 詳細DDLは付録Aを参照。

---

## 9. API仕様（例）
- `GET /topics`  
- `GET /topics/{topic_id}/positions?mode=claim|action|combined&entity=party|party+politician`（座標/レンジ/更新日時/信頼度）  
- `GET /entities/{entity_id}/topics/{topic_id}/detail?mode=...`（スコア＋根拠＋抜粋＋版本情報）
- `GET /topics/{topic_id}/rubric`（評価基準）

管理系（内部）:  
- `POST /admin/parties/discover`  
- `PUT /admin/parties/{party_id}/policy-sources`（政策URL登録）  
- `POST /admin/parties/{party_id}/policy-sources/crawl`（クロール実行）  
- `POST /admin/topics/{topic_id}/scores/run`（公式/混合のスコアリング）  
- `GET /admin/topics/{topic_id}/scores/latest`

将来予定（キュー駆動）:  
- `POST /admin/discovery/run`  
- `POST /admin/resolve/run`  
- `POST /admin/crawl/run`  
- `POST /admin/score/run`

---

## 10. イベント駆動（キュー）設計

### 10.1 トピック
- `party.resolve`: 候補 → 公式URL確定  
- `party.crawl`: クロール実行  
- `party.score`: 採点実行

### 10.2 冪等性
- `party_discovery_events.idempotency_key` をユニークにし重複イベントを防止  
- 公式URL確定・登録は `canonical_key`（正規化党名）ベースで upsert

---

## 11. 非機能要件

### 11.1 品質・透明性
- 根拠URLがないスコアは公開不可（不明扱い）  
- バージョン（`topic_version` / `calc_version`）表示必須

### 11.2 性能
- 可視化APIはキャッシュ前提（集計テーブル/Redis等）  
- バッチは差分更新（hash変化があるページのみ再解析）
- 静的公開時は `snapshot.json` を参照してAPIを公開しない構成も可能

### 11.3 セキュリティ
- 管理APIは認証必須  
- allowlist以外の取得禁止（SSRF対策）

---

## 12. 運用要件
- `needs_review` に入った政党候補を管理画面で確認し、手動で `verified` へ昇格可能  
- 党名表記揺れ（略称/旧称）を別名として紐付けできる  
- ソーススナップショット保管期限・外部ストレージ連携（任意）

---

## 13. フロントエンド技術選定（現状 → 将来）

- 現状: **HTML/CSS/JavaScript の静的構成**（`frontend/` 配下）  
  - 1軸/2軸の可視化、詳細オーバーレイ、テーマ切替、ルーブリック表示を提供  
- 将来: **Vite + React + TypeScript** への移行を検討  
  - グラフ描画は **Apache ECharts** を採用予定  
  - 動的な1軸/2軸切替・レンジ表示・ツールチップ等を少ないコードで実装しやすい  
  - EChartsは散布図・レンジ帯（custom series）・ライン/ヒートマップ等が充実  
  - 状態管理: **Zustand**（軽量で学習コストが低い）  
  - スタイル: **CSS Modules or Tailwind CSS** のいずれかを選択  
  - API連携: `.env` に `VITE_API_BASE` を設定（将来のビルド前提）

---

## 付録A: DB DDL（PostgreSQL）

前提: PostgreSQL を想定。`gen_random_uuid()` を利用するため、必要に応じて pgcrypto を有効化する。

```sql
-- UUID生成のため（必要に応じて）
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- 1) Enum
DO $$ BEGIN
  CREATE TYPE party_status AS ENUM ('candidate', 'verified', 'needs_review', 'rejected');
EXCEPTION
  WHEN duplicate_object THEN NULL;
END $$;

DO $$ BEGIN
  CREATE TYPE discovery_action AS ENUM ('added', 'updated', 'removed');
EXCEPTION
  WHEN duplicate_object THEN NULL;
END $$;

DO $$ BEGIN
  CREATE TYPE evidence_type AS ENUM (
    'official_link_list',
    'election_commission_list',
    'official_site_self_declare',
    'manual_review'
  );
EXCEPTION
  WHEN duplicate_object THEN NULL;
END $$;

-- 2) 政党レジストリ（新党の自動登録の最終成果物）
CREATE TABLE IF NOT EXISTS party_registry (
  party_id           UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name_ja            TEXT NOT NULL,
  name_en            TEXT,
  status             party_status NOT NULL DEFAULT 'candidate',

  official_home_url  TEXT,                           -- 確定した公式トップURL
  allowed_domains    TEXT[] NOT NULL DEFAULT '{}',   -- クローラ許可ドメイン（例: ['example-party.jp']）

  confidence         NUMERIC(4,3) NOT NULL DEFAULT 0.000, -- 0.000 - 1.000
  evidence           JSONB NOT NULL DEFAULT '[]'::jsonb,  -- 根拠配列

  first_seen_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
  last_checked_at    TIMESTAMPTZ NOT NULL DEFAULT now(),
  verified_at        TIMESTAMPTZ,

  -- 党名の正規化キー（空白除去・小文字化など簡易）
  canonical_key      TEXT GENERATED ALWAYS AS (lower(regexp_replace(name_ja, '\\s+', '', 'g'))) STORED,

  created_at         TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at         TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX IF NOT EXISTS idx_party_registry_status ON party_registry(status);
CREATE INDEX IF NOT EXISTS idx_party_registry_canonical_key ON party_registry(canonical_key);
CREATE INDEX IF NOT EXISTS idx_party_registry_allowed_domains_gin ON party_registry USING GIN (allowed_domains);
CREATE INDEX IF NOT EXISTS idx_party_registry_evidence_gin ON party_registry USING GIN (evidence);

-- updated_at 自動更新
CREATE OR REPLACE FUNCTION set_updated_at()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS trg_party_registry_updated_at ON party_registry;
CREATE TRIGGER trg_party_registry_updated_at
BEFORE UPDATE ON party_registry
FOR EACH ROW EXECUTE FUNCTION set_updated_at();

-- 3) 発見イベント（差分検知ログ）
CREATE TABLE IF NOT EXISTS party_discovery_events (
  event_id        UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_name     TEXT NOT NULL,     -- e.g. 'sangiin_party_links'
  source_url      TEXT NOT NULL,
  action          discovery_action NOT NULL,
  observed_at     TIMESTAMPTZ NOT NULL DEFAULT now(),

  party_name_ja   TEXT NOT NULL,
  candidate_url   TEXT,              -- 発見時点のリンク先（あれば）
  extracted_text  TEXT,              -- 根拠抜粋（リンク周辺テキストなど）

  payload         JSONB NOT NULL DEFAULT '{}'::jsonb, -- 追加情報（HTML断片、パース結果など）
  snapshot_hash   TEXT,              -- その時点のソーススナップショットhash
  idempotency_key TEXT UNIQUE        -- 冪等（同一イベント重複防止）
);

CREATE INDEX IF NOT EXISTS idx_discovery_events_observed_at ON party_discovery_events(observed_at);
CREATE INDEX IF NOT EXISTS idx_discovery_events_source_name ON party_discovery_events(source_name);

-- 4) ソーススナップショット（差分検知用）
CREATE TABLE IF NOT EXISTS source_snapshots (
  snapshot_id     UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_name     TEXT NOT NULL,
  source_url      TEXT NOT NULL,
  fetched_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
  content_hash    TEXT NOT NULL,
  content         BYTEA,             -- 重い場合はNULL + 外部ストレージ参照にする
  meta            JSONB NOT NULL DEFAULT '{}'::jsonb
);

CREATE INDEX IF NOT EXISTS idx_source_snapshots_source_name ON source_snapshots(source_name);
CREATE INDEX IF NOT EXISTS idx_source_snapshots_fetched_at ON source_snapshots(fetched_at);

-- 5) 変更履歴（公式URL変更、ドメイン追加、ステータス遷移など）
CREATE TABLE IF NOT EXISTS party_change_history (
  change_id     UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  party_id      UUID NOT NULL REFERENCES party_registry(party_id) ON DELETE CASCADE,
  changed_at    TIMESTAMPTZ NOT NULL DEFAULT now(),
  change_type   TEXT NOT NULL,        -- e.g. 'status_change', 'official_url_change', 'allowed_domain_change'
  before_state  JSONB NOT NULL,
  after_state   JSONB NOT NULL,
  reason        TEXT,
  evidence      JSONB NOT NULL DEFAULT '[]'::jsonb
);

CREATE INDEX IF NOT EXISTS idx_party_change_history_party_id ON party_change_history(party_id);
CREATE INDEX IF NOT EXISTS idx_party_change_history_changed_at ON party_change_history(changed_at);
```

---

## 付録B: AIエージェント疑似コード（Python）

「政党の自動発見（Discovery）→公式URL特定（Resolution）→登録（Registry）→クロール/採点トリガ」までの処理を示す。LLMは抽出補助や表記揺れ補正などの補助に限定し、公式URL確定は「公的リンク等の証拠」と「到達確認」で行う。すべてのイベントは冪等キー（`idempotency_key`）で重複実行に耐える。

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import hashlib
import re
import time
from urllib.parse import urljoin, urlparse

import requests
from bs4 import BeautifulSoup


# -----------------------------
# Utilities
# -----------------------------

def norm_party_name(name: str) -> str:
    """党名の簡易正規化（空白除去・小文字化）。必要に応じて拡張する。"""
    s = re.sub(r"\s+", "", name.strip())
    return s.lower()


def sha256_bytes(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()


def get_domain(url: str) -> str:
    return urlparse(url).netloc.lower()


def fetch(url: str, *, timeout: int = 20) -> bytes:
    r = requests.get(url, timeout=timeout, allow_redirects=True, headers={"User-Agent": "PartyVizBot/1.0"})
    r.raise_for_status()
    return r.content


def resolve_reachable_url(url: str, *, timeout: int = 10) -> Tuple[bool, str]:
    """URL到達確認 + リダイレクト後の最終URLを返す"""
    try:
        r = requests.get(url, timeout=timeout, allow_redirects=True, headers={"User-Agent": "PartyVizBot/1.0"})
        return (200 <= r.status_code < 400), r.url
    except Exception:
        return False, url


# -----------------------------
# Abstractions
# -----------------------------

class Queue:
    def publish(self, topic: str, payload: Dict[str, Any], idempotency_key: Optional[str] = None) -> None:
        raise NotImplementedError


class DB:
    def upsert_snapshot(self, source_name: str, source_url: str, content_hash: str, content: bytes, meta: Dict[str, Any]) -> str:
        """returns snapshot_id"""
        raise NotImplementedError

    def get_latest_snapshot_hash(self, source_name: str, source_url: str) -> Optional[str]:
        raise NotImplementedError

    def insert_discovery_event(
        self,
        *,
        source_name: str,
        source_url: str,
        action: str,
        party_name_ja: str,
        candidate_url: Optional[str],
        extracted_text: str,
        payload: Dict[str, Any],
        snapshot_hash: str,
        idempotency_key: str,
    ) -> None:
        raise NotImplementedError

    def create_or_update_party_candidate(self, *, name_ja: str, evidence_item: Dict[str, Any]) -> str:
        """returns party_id"""
        raise NotImplementedError

    def mark_party_verified(
        self,
        *,
        party_id: str,
        official_home_url: str,
        allowed_domains: List[str],
        confidence: float,
        evidence_item: Dict[str, Any],
    ) -> None:
        raise NotImplementedError

    def update_party_status(
        self,
        *,
        party_id: str,
        status: str,
        confidence: float,
        evidence_item: Dict[str, Any],
        reason: str,
    ) -> None:
        raise NotImplementedError


# -----------------------------
# Source config
# -----------------------------

@dataclass
class SourceConfig:
    source_name: str
    source_url: str
    evidence_type: str  # 'official_link_list' / 'election_commission_list'
    rate_limit_sec: float = 1.0


# -----------------------------
# Discovery Agent
# -----------------------------

class DiscoveryAgent:
    """公的ページ等から政党候補を抽出し、差分があれば Resolve キューへ投入する。"""

    def __init__(self, db: DB, queue: Queue, sources: List[SourceConfig]):
        self.db = db
        self.queue = queue
        self.sources = sources

    def run(self) -> None:
        for src in self.sources:
            self._run_one(src)
            time.sleep(src.rate_limit_sec)

    def _run_one(self, src: SourceConfig) -> None:
        html = fetch(src.source_url)
        snapshot_hash = sha256_bytes(html)

        prev_hash = self.db.get_latest_snapshot_hash(src.source_name, src.source_url)
        if prev_hash == snapshot_hash:
            return  # no change

        self.db.upsert_snapshot(
            src.source_name,
            src.source_url,
            snapshot_hash,
            html,
            meta={"evidence_type": src.evidence_type},
        )

        parties = self._extract_parties_from_link_list(src, html)

        # MVP: 抽出結果をすべてイベント化（本番では前回抽出結果を保存して diff 判定する）
        for p in parties:
            idem = f"{src.source_name}:{snapshot_hash}:{norm_party_name(p['name_ja'])}:{p.get('url','')}"

            self.db.insert_discovery_event(
                source_name=src.source_name,
                source_url=src.source_url,
                action="added",
                party_name_ja=p["name_ja"],
                candidate_url=p.get("url"),
                extracted_text=p.get("context", ""),
                payload={"raw": p},
                snapshot_hash=snapshot_hash,
                idempotency_key=idem,
            )

            self.queue.publish(
                topic="party.resolve",
                payload={
                    "source_name": src.source_name,
                    "source_url": src.source_url,
                    "snapshot_hash": snapshot_hash,
                    "party_name_ja": p["name_ja"],
                    "candidate_url": p.get("url"),
                    "evidence_type": src.evidence_type,
                    "extracted_text": p.get("context", ""),
                },
                idempotency_key=idem,
            )

    def _extract_parties_from_link_list(self, src: SourceConfig, html: bytes) -> List[Dict[str, Any]]:
        soup = BeautifulSoup(html, "html.parser")
        results: List[Dict[str, Any]] = []

        # 公的リンク集など「政党名 + href」が並ぶページを想定
        for a in soup.select("a[href]"):
            name = a.get_text(strip=True)
            href = (a.get("href") or "").strip()
            if not name or not href:
                continue
            if len(name) < 2:
                continue

            url = href if href.startswith("http") else urljoin(src.source_url, href)
            context = (a.parent.get_text(" ", strip=True)[:300] if a.parent else name)
            results.append({"name_ja": name, "url": url, "context": context})

        return results


# -----------------------------
# Resolution Agent
# -----------------------------

class ResolutionAgent:
    """候補（candidate）から公式URLを根拠付きで確定し、verified/needs_review を決める。"""

    def __init__(self, db: DB, queue: Queue):
        self.db = db
        self.queue = queue

    def handle(self, msg: Dict[str, Any]) -> None:
        name_ja = msg["party_name_ja"]
        candidate_url = msg.get("candidate_url")

        evidence_item = {
            "source_url": msg.get("source_url"),
            "observed_at": msg.get("observed_at", time.time()),
            "evidence_type": msg.get("evidence_type", "official_link_list"),
            "extracted_text": msg.get("extracted_text", ""),
            "target_url": candidate_url,
        }

        party_id = self.db.create_or_update_party_candidate(name_ja=name_ja, evidence_item=evidence_item)

        # 公式URL確定ルール（自動確定できるのは「公的リンク等の証拠 + 到達確認」満たす場合）
        if candidate_url:
            ok, final_url = resolve_reachable_url(candidate_url)
            if ok:
                allowed = [get_domain(final_url)]

                confidence = 0.95 if evidence_item["evidence_type"] == "official_link_list" else 0.85

                self.db.mark_party_verified(
                    party_id=party_id,
                    official_home_url=final_url,
                    allowed_domains=allowed,
                    confidence=confidence,
                    evidence_item=evidence_item,
                )

                # 次工程（クロール・採点）
                self.queue.publish("party.crawl", {"party_id": party_id, "seed_url": final_url, "allowed_domains": allowed})
                self.queue.publish("party.score", {"party_id": party_id})
                return

        # URL未確定 or 到達不可 → 自動確定せず要レビュー
        self.db.update_party_status(
            party_id=party_id,
            status="needs_review",
            confidence=0.4,
            evidence_item=evidence_item,
            reason="No resolvable official URL from authoritative source or unreachable URL.",
        )
```

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import hashlib
import re
import time
from urllib.parse import urljoin, urlparse

import requests
from bs4 import BeautifulSoup


# -----------------------------
# Utilities
# -----------------------------

def norm_party_name(name: str) -> str:
    """党名の簡易正規化（空白除去・小文字化）。必要に応じて拡張する。"""
    s = re.sub(r"\s+", "", name.strip())
    return s.lower()


def sha256_bytes(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()


def get_domain(url: str) -> str:
    return urlparse(url).netloc.lower()


def fetch(url: str, *, timeout: int = 20) -> bytes:
    r = requests.get(url, timeout=timeout, allow_redirects=True, headers={"User-Agent": "PartyVizBot/1.0"})
    r.raise_for_status()
    return r.content


def resolve_reachable_url(url: str, *, timeout: int = 10) -> Tuple[bool, str]:
    """URL到達確認 + リダイレクト後の最終URLを返す"""
    try:
        r = requests.get(url, timeout=timeout, allow_redirects=True, headers={"User-Agent": "PartyVizBot/1.0"})
        return (200 <= r.status_code < 400), r.url
    except Exception:
        return False, url


# -----------------------------
# Abstractions
# -----------------------------

class Queue:
    def publish(self, topic: str, payload: Dict[str, Any], idempotency_key: Optional[str] = None) -> None:
        raise NotImplementedError


class DB:
    def upsert_snapshot(self, source_name: str, source_url: str, content_hash: str, content: bytes, meta: Dict[str, Any]) -> str:
        """returns snapshot_id"""
        raise NotImplementedError

    def get_latest_snapshot_hash(self, source_name: str, source_url: str) -> Optional[str]:
        raise NotImplementedError

    def insert_discovery_event(
        self,
        *,
        source_name: str,
        source_url: str,
        action: str,
        party_name_ja: str,
        candidate_url: Optional[str],
        extracted_text: str,
        payload: Dict[str, Any],
        snapshot_hash: str,
        idempotency_key: str,
    ) -> None:
        raise NotImplementedError

    def create_or_update_party_candidate(self, *, name_ja: str, evidence_item: Dict[str, Any]) -> str:
        """returns party_id"""
        raise NotImplementedError

    def mark_party_verified(
        self,
        *,
        party_id: str,
        official_home_url: str,
        allowed_domains: List[str],
        confidence: float,
        evidence_item: Dict[str, Any],
    ) -> None:
        raise NotImplementedError

    def update_party_status(
        self,
        *,
        party_id: str,
        status: str,
        confidence: float,
        evidence_item: Dict[str, Any],
        reason: str,
    ) -> None:
        raise NotImplementedError


# -----------------------------
# Source config
# -----------------------------

@dataclass
class SourceConfig:
    source_name: str
    source_url: str
    evidence_type: str  # 'official_link_list' / 'election_commission_list'
    rate_limit_sec: float = 1.0


# -----------------------------
# Discovery Agent
# -----------------------------

class DiscoveryAgent:
    """公的ページ等から政党候補を抽出し、差分があれば Resolve キューへ投入する。"""

    def __init__(self, db: DB, queue: Queue, sources: List[SourceConfig]):
        self.db = db
        self.queue = queue
        self.sources = sources

    def run(self) -> None:
        for src in self.sources:
            self._run_one(src)
            time.sleep(src.rate_limit_sec)

    def _run_one(self, src: SourceConfig) -> None:
        html = fetch(src.source_url)
        snapshot_hash = sha256_bytes(html)

        prev_hash = self.db.get_latest_snapshot_hash(src.source_name, src.source_url)
        if prev_hash == snapshot_hash:
            return  # no change

        self.db.upsert_snapshot(
            src.source_name,
            src.source_url,
            snapshot_hash,
            html,
            meta={"evidence_type": src.evidence_type},
        )

        parties = self._extract_parties_from_link_list(src, html)

        # MVP: 抽出結果をすべてイベント化（本番では前回抽出結果を保存して diff 判定する）
        for p in parties:
            idem = f"{src.source_name}:{snapshot_hash}:{norm_party_name(p['name_ja'])}:{p.get('url','')}"

            self.db.insert_discovery_event(
                source_name=src.source_name,
                source_url=src.source_url,
                action="added",
                party_name_ja=p["name_ja"],
                candidate_url=p.get("url"),
                extracted_text=p.get("context", ""),
                payload={"raw": p},
                snapshot_hash=snapshot_hash,
                idempotency_key=idem,
            )

            self.queue.publish(
                topic="party.resolve",
                payload={
                    "source_name": src.source_name,
                    "source_url": src.source_url,
                    "snapshot_hash": snapshot_hash,
                    "party_name_ja": p["name_ja"],
                    "candidate_url": p.get("url"),
                    "evidence_type": src.evidence_type,
                    "extracted_text": p.get("context", ""),
                },
                idempotency_key=idem,
            )

    def _extract_parties_from_link_list(self, src: SourceConfig, html: bytes) -> List[Dict[str, Any]]:
        soup = BeautifulSoup(html, "html.parser")
        results: List[Dict[str, Any]] = []

        # 公的リンク集など「政党名 + href」が並ぶページを想定
        for a in soup.select("a[href]"):
            name = a.get_text(strip=True)
            href = (a.get("href") or "").strip()
            if not name or not href:
                continue
            if len(name) < 2:
                continue

            url = href if href.startswith("http") else urljoin(src.source_url, href)
            context = (a.parent.get_text(" ", strip=True)[:300] if a.parent else name)
            results.append({"name_ja": name, "url": url, "context": context})

        return results


# -----------------------------
# Resolution Agent
# -----------------------------

class ResolutionAgent:
    """候補（candidate）から公式URLを根拠付きで確定し、verified/needs_review を決める。"""

    def __init__(self, db: DB, queue: Queue):
        self.db = db
        self.queue = queue

    def handle(self, msg: Dict[str, Any]) -> None:
        name_ja = msg["party_name_ja"]
        candidate_url = msg.get("candidate_url")

        evidence_item = {
            "source_url": msg.get("source_url"),
            "observed_at": msg.get("observed_at", time.time()),
            "evidence_type": msg.get("evidence_type", "official_link_list"),
            "extracted_text": msg.get("extracted_text", ""),
            "target_url": candidate_url,
        }

        party_id = self.db.create_or_update_party_candidate(name_ja=name_ja, evidence_item=evidence_item)

        # 公式URL確定ルール（自動確定できるのは「公的リンク等の証拠 + 到達確認」満たす場合）
        if candidate_url:
            ok, final_url = resolve_reachable_url(candidate_url)
            if ok:
                allowed = [get_domain(final_url)]

                confidence = 0.95 if evidence_item["evidence_type"] == "official_link_list" else 0.85

                self.db.mark_party_verified(
                    party_id=party_id,
                    official_home_url=final_url,
                    allowed_domains=allowed,
                    confidence=confidence,
                    evidence_item=evidence_item,
                )

                # 次工程（クロール・採点）
                self.queue.publish("party.crawl", {"party_id": party_id, "seed_url": final_url, "allowed_domains": allowed})
                self.queue.publish("party.score", {"party_id": party_id})
                return

        # URL未確定 or 到達不可 → 自動確定せず要レビュー
        self.db.update_party_status(
            party_id=party_id,
            status="needs_review",
            confidence=0.4,
            evidence_item=evidence_item,
            reason="No resolvable official URL from authoritative source or unreachable URL.",
        )
