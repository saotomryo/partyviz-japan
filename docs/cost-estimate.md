# コスト見積もり（A案: LLM Web検索 + 公式URL検証）

## 前提
本アプリのコアは「Web検索/grounding可能なLLM」による以下の一連です。
1) 政党の公式URL特定（Discovery）
2) 各政党の公式ドメイン内からトピック関連ページURL＋引用を抽出（Evidence）
3) 抽出した本文を入力として相対スコアを算出（Score）

## コストの支配要因
- **LLM呼び出し回数**（Discovery/Evidence/Score の3呼び出しを最小構成にするのが安い）
- **Web検索/groundingの有無**（検索機能が有料オプション/別課金の場合がある）
- **入出力トークン量**（本文を多く渡すほど増える）
- **対象政党数 × トピック数**（線形に増える）

## 推奨の最小呼び出し設計（1トピックあたり）
- Discovery: 1回（主要政党の official_url をまとめて返す）
- Evidence: 1回（政党リストを入力に、各党最大N件の evidence_url+quote を返す）
- Score: 1回（各党の本文テキストをまとめて相対評価）

合計: **3リクエスト / topic**

## 入力サイズの上限（運用目安）
- Evidenceで取得するURL数: `N=3`（各党）
- 1ページ本文: `8,000` 文字程度に切り詰めて入力
- 党数: `P`

スコアリング入力の概算文字数: `P * N * 8,000`

## 実測ベースでの見積もり方法
正確な単価はモデル・契約・検索機能の課金体系で変わるため、以下をログに残して実測で見積もる。
- (OpenAI) `usage.prompt_tokens` / `usage.completion_tokens`（APIレスポンスに含まれる）
- (Gemini) 可能なら同等の使用量指標（SDK/レスポンス仕様に依存）
- 1トピック実行での呼び出し回数（Discovery/Evidence/Score）

見積もり手順:
1) 代表トピックを1つ選び、P政党で1回実行
2) 各リクエストのトークン使用量を合計
3) 公式の料金表に当てはめて「1トピックあたり」「全トピックあたり」に換算

## OpenAI / Gemini 併用時の考え方
- 検索/groundingが安い方を **Discovery/Evidence** に採用し、スコアリングは精度が高い方を **Score** に採用する、という分業がコスト最適化に効く。
- ただし、同一トピックで複数プロバイダを混ぜると差分検証工数が増えるため、最初は片方でPoCを確立し、後から比較するのが安全。
